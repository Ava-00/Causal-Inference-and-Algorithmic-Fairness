{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8Al19884EmEe3G343xppr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ava-00/Causal-Inference-and-Algorithmic-Fairness/blob/main/Kusner_Paper_Simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pystan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah0jzxQjfwp3",
        "outputId": "def02b14-4502-4b4f-d75b-36c24d5df123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pystan\n",
            "  Downloading pystan-3.10.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.6 in /usr/local/lib/python3.10/dist-packages (from pystan) (3.10.10)\n",
            "Collecting clikit<0.7,>=0.6 (from pystan)\n",
            "  Downloading clikit-0.6.2-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting httpstan<4.14,>=4.13 (from pystan)\n",
            "  Downloading httpstan-4.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from pystan) (1.26.4)\n",
            "Collecting pysimdjson<7,>=5.0.2 (from pystan)\n",
            "  Downloading pysimdjson-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pystan) (75.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->pystan) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->pystan) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->pystan) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->pystan) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->pystan) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->pystan) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->pystan) (4.0.3)\n",
            "Collecting crashtest<0.4.0,>=0.3.0 (from clikit<0.7,>=0.6->pystan)\n",
            "  Downloading crashtest-0.3.1-py3-none-any.whl.metadata (748 bytes)\n",
            "Collecting pastel<0.3.0,>=0.2.0 (from clikit<0.7,>=0.6->pystan)\n",
            "  Downloading pastel-0.2.1-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting pylev<2.0,>=1.3 (from clikit<0.7,>=0.6->pystan)\n",
            "  Downloading pylev-1.4.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting appdirs<2.0,>=1.4 (from httpstan<4.14,>=4.13->pystan)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting marshmallow<4.0,>=3.10 (from httpstan<4.14,>=4.13->pystan)\n",
            "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting webargs<9.0,>=8.0 (from httpstan<4.14,>=4.13->pystan)\n",
            "  Downloading webargs-8.6.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0,>=3.10->httpstan<4.14,>=4.13->pystan) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp<4.0,>=3.6->pystan) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0,>=3.6->pystan) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0,>=3.6->pystan) (0.2.0)\n",
            "Downloading pystan-3.10.0-py3-none-any.whl (13 kB)\n",
            "Downloading clikit-0.6.2-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpstan-4.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysimdjson-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading crashtest-0.3.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pastel-0.2.1-py2.py3-none-any.whl (6.0 kB)\n",
            "Downloading pylev-1.4.0-py2.py3-none-any.whl (6.1 kB)\n",
            "Downloading webargs-8.6.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: pylev, appdirs, pysimdjson, pastel, marshmallow, crashtest, webargs, clikit, httpstan, pystan\n",
            "Successfully installed appdirs-1.4.4 clikit-0.6.2 crashtest-0.3.1 httpstan-4.13.0 marshmallow-3.23.0 pastel-0.2.1 pylev-1.4.0 pysimdjson-6.0.2 pystan-3.10.0 webargs-8.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnGRymbmc4kZ",
        "outputId": "2759239b-6925-4b90-c7e3-bb11cd7f0a80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unfair Model RMSE: 0.9925913708802588\n",
            "Unaware Model RMSE: 0.9862696224094137\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Number of samples\n",
        "n_samples = 1000\n",
        "\n",
        "# Create race as categorical values without predefined proportions\n",
        "races = [\"White\", \"Hispanic\", \"Black\", \"Asian\", \"Amerind\", \"Other\"]\n",
        "data = pd.DataFrame({\n",
        "    \"race\": np.random.choice(races, size=n_samples),\n",
        "    \"sex\": np.random.choice([1, 0], size=n_samples, p=[0.5, 0.5]),\n",
        "    \"region_first\": np.random.choice([\"GL\", \"MS\", \"NE\", \"SE\", \"SW\", \"W\"], size=n_samples),\n",
        "    \"UGPA\": np.random.normal(3.5, 0.4, n_samples).round(1),\n",
        "    \"ZFYA\": np.random.normal(0, 1, n_samples).round(2),  # Normal distribution centered around 0 for simplicity\n",
        "    \"sander_index\": np.random.uniform(0.6, 0.8, n_samples).round(10),\n",
        "    \"first_pf\": 1.0\n",
        "})\n",
        "\n",
        "data = pd.get_dummies(data, columns=[\"race\", \"region_first\"], drop_first=False)\n",
        "\n",
        "data[\"LSAT\"] = np.random.poisson(35, n_samples).round(1)\n",
        "\n",
        "sensitive_columns = [col for col in data.columns if col.startswith(\"race_\") or col.startswith(\"region_first_\") or col == \"sex\"]\n",
        "a = data[sensitive_columns].values\n",
        "\n",
        "# Create input data for the model\n",
        "stan_data = {\n",
        "    'N': n_samples,\n",
        "    'K': a.shape[1],\n",
        "    'a': a,\n",
        "    'ugpa': data['UGPA'].values,\n",
        "    'lsat': data['LSAT'].values.astype(int),\n",
        "    'zfya': data['ZFYA'].values\n",
        "}\n",
        "\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=0)\n",
        "\n",
        "# Model Configuration\n",
        "X_train_unfair = train_data[sensitive_columns + [\"LSAT\", \"UGPA\"]]\n",
        "X_test_unfair = test_data[sensitive_columns + [\"LSAT\", \"UGPA\"]]\n",
        "y_train = train_data[\"ZFYA\"]\n",
        "y_test = test_data[\"ZFYA\"]\n",
        "\n",
        "model_unfair = LinearRegression().fit(X_train_unfair, y_train)\n",
        "pred_unfair_test = model_unfair.predict(X_test_unfair)\n",
        "rmse_unfair_test = np.sqrt(mean_squared_error(y_test, pred_unfair_test))\n",
        "print(f\"Unfair Model RMSE: {rmse_unfair_test}\")\n",
        "\n",
        "# Model Unaware (sensitive features not included)\n",
        "X_train_unaware = train_data[[\"LSAT\", \"UGPA\"]]\n",
        "X_test_unaware = test_data[[\"LSAT\", \"UGPA\"]]\n",
        "\n",
        "model_unaware = LinearRegression().fit(X_train_unaware, y_train)\n",
        "pred_unaware_test = model_unaware.predict(X_test_unaware)\n",
        "rmse_unaware_test = np.sqrt(mean_squared_error(y_test, pred_unaware_test))\n",
        "print(f\"Unaware Model RMSE: {rmse_unaware_test}\")\n",
        "\n",
        "# Fair model (accounting for sensitive features and performing multiple abduction steps)\n",
        "stan_model_code = \"\"\"\n",
        "data {\n",
        "  int<lower=0> N;\n",
        "  int<lower=0> K;\n",
        "  matrix[N, K] a;\n",
        "  vector[N] ugpa;\n",
        "  vector[N] lsat;\n",
        "  vector[N] zfya;\n",
        "}\n",
        "parameters {\n",
        "  real ugpa0;\n",
        "  real eta_u_ugpa;\n",
        "  vector[K] eta_a_ugpa;\n",
        "  real lsat0;\n",
        "  real eta_u_lsat;\n",
        "  vector[K] eta_a_lsat;\n",
        "  real sigma_g;\n",
        "  vector[N] u;\n",
        "}\n",
        "model {\n",
        "  zfya ~ normal(ugpa + lsat + u, sigma_g);\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training data in the format required for PyStan\n",
        "import stan\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Prepare the data for PyStan\n",
        "stan_data_train = {\n",
        "    'N': len(train_data),\n",
        "    'K': len(sensitive_columns),\n",
        "    'a': train_data[sensitive_columns].values,\n",
        "    'ugpa': train_data['UGPA'].values,  # Target variable UGPA\n",
        "    'lsat': train_data['LSAT'].values,  # Target variable LSAT\n",
        "    'zfya': train_data['ZFYA'].values   # Additional target variable ZFYA\n",
        "}\n",
        "\n",
        "# # Interesting way to sample! Fit a Bayesian Model using pystan and sample from the posterior distribution\n",
        "# posterior = stan.build(stan_model_code, data=stan_data_train)\n",
        "# fit = posterior.sample(num_chains=1, num_samples=2000)  # Sample from posterior\n",
        "\n",
        "# # Extract the model parameters\n",
        "# # fit_results = fit.to_frame()  # Extract results as a pandas DataFrame\n",
        "# # u_cols = [col for col in fit_results.columns if col.startswith('u[')]\n",
        "# # u_train = fit_results[u_cols].mean(axis=0)\n",
        "\n",
        "# Train deterministic model for fair approach\n",
        "residual_ugpa_model = LinearRegression().fit(train_data[sensitive_columns], train_data[\"UGPA\"])\n",
        "train_data[\"resid_UGPA\"] = train_data[\"UGPA\"] - residual_ugpa_model.predict(train_data[sensitive_columns])\n",
        "\n",
        "residual_lsat_model = LinearRegression().fit(train_data[sensitive_columns], train_data[\"LSAT\"])\n",
        "train_data[\"resid_LSAT\"] = train_data[\"LSAT\"] - residual_lsat_model.predict(train_data[sensitive_columns])\n",
        "\n",
        "# Fair deterministic model on residuals\n",
        "X_fair_train = train_data[[\"resid_UGPA\", \"resid_LSAT\"]]\n",
        "model_fair_det = LinearRegression().fit(X_fair_train, y_train)\n",
        "\n",
        "# Calculate RMSE for test data using fair deterministic model\n",
        "test_data[\"resid_UGPA\"] = test_data[\"UGPA\"] - residual_ugpa_model.predict(test_data[sensitive_columns])\n",
        "test_data[\"resid_LSAT\"] = test_data[\"LSAT\"] - residual_lsat_model.predict(test_data[sensitive_columns])\n",
        "X_fair_test = test_data[[\"resid_UGPA\", \"resid_LSAT\"]]\n",
        "\n",
        "# Predict and calculate RMSE\n",
        "pred_fair_test = model_fair_det.predict(X_fair_test)\n",
        "rmse_fair_test = np.sqrt(mean_squared_error(y_test, pred_fair_test))\n",
        "print(f\"Fair Deterministic Model RMSE: {rmse_fair_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctFeyLB0fjAZ",
        "outputId": "91c6bb24-d681-4eb8-acc3-22cd2c4b52b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fair Deterministic Model RMSE: 0.9864374191531695\n"
          ]
        }
      ]
    }
  ]
}